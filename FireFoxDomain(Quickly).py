import os
import time
import random
import tldextract
import argparse
from colorama import init, Fore, Style
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.service import Service
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import (
    TimeoutException,
    StaleElementReferenceException,
    NoSuchElementException
)
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
from email.utils import formataddr

# åˆå§‹åŒ–é…ç½®
init(autoreset=True)

# æ ¸å¿ƒé…ç½®
SCROLL_PAUSE = 0.25  # æ»šåŠ¨ç­‰å¾…æ—¶é—´
CLICK_RETRY = 1  # æŒ‰é’®ç‚¹å‡»é‡è¯•æ¬¡æ•°
MAX_EMPTY_ATTEMPTS = 99  # æœ€å¤§è¿ç»­ç©ºç»“æœè½®æ¬¡
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0"
RESULTS_FOLDER = "results"  # ç»“æœæ–‡ä»¶å¤¹åç§°


def print_banner():
    """æ˜¾ç¤ºç¨‹åºæ¨ªå¹…"""
    banner = r"""
                                                                                           ):)
                                                                                         (:::(
                                                                                         ):::::)
   _     ___/\\____________________________/))__ _  (:::::::)
 (::(  \ |         __________                                              |...):::::::)
  \::\  (        (__________,)                                          _|\::)
    \::\   )            __            ____________________|\:::|/
      Â¯  /Â¤Â¤Â¤Â¤Â¤Â¤(    (   (::( Â¯Â¯)\:::::::::::::::::::::::::::::::::::::\|Â¯
         /Â¤Â¤Â¤Â¤Â¤Â¤Â¤\\    \_.\::\   /:::/Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
        /Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤\ \______/::'/
       /Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤/\ :::::::::::\:/
      /Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤):::)Â¯Â¯Â¯Â¯Â¯
     /Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤/:::/
 _ /Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤Â¤/:::/
(  Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯\::/     BY : Bifish
  Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯Â¯
    """
    print(Fore.CYAN + banner)
    print(Fore.GREEN + "=" * 60)
    print(Fore.YELLOW + "  åŸºäºFirefoxçš„å­åŸŸæ·±åº¦çˆ¬å–å™¨(æ€§èƒ½ä¼˜åŒ–ç‰ˆ) - è¾‰å°é±¼")
    print(Fore.RED + "  åŠŸèƒ½ï¼šé€Ÿåº¦ä¼˜åŒ–ï¼Œæ€§èƒ½æ‹‰æ»¡~~~")
    print(Fore.GREEN + "=" * 60)
    print(Style.RESET_ALL)


def create_results_folder():
    """åˆ›å»º results æ–‡ä»¶å¤¹ï¼ˆè‹¥ä¸å­˜åœ¨ï¼‰"""
    if not os.path.exists(RESULTS_FOLDER):
        os.makedirs(RESULTS_FOLDER)
        print(Fore.GREEN + f"[+] åˆ›å»ºç»“æœæ–‡ä»¶å¤¹: {RESULTS_FOLDER}")


def setup_driver(proxy=None):
    """åˆå§‹åŒ–æµè§ˆå™¨å¹¶åº”ç”¨åæ£€æµ‹é…ç½®"""
    service = Service("geckodriver.exe")  # æ›¿æ¢ä¸ºä½ çš„é©±åŠ¨è·¯å¾„
    options = Options()

    # åæ£€æµ‹é…ç½®
    options.add_argument("--start-maximized")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-web-security")
    options.add_argument("--disable-features=IsolateOrigins,site-per-process")
    options.add_argument("--disable-site-isolation-trials")

    # æµè§ˆå™¨æŒ‡çº¹ä¼ªè£…
    options.set_preference("dom.webdriver.enabled", False)
    options.set_preference("useAutomationExtension", False)
    options.set_preference("general.useragent.override", USER_AGENT)
    options.set_preference("browser.cache.disk.enable", False)
    options.set_preference("browser.cache.memory.enable", False)

    # é…ç½®ä»£ç†
    if proxy:
        proxy_parts = proxy.split(':')
        if len(proxy_parts) == 2:
            host, port = proxy_parts
            options.set_preference("network.proxy.type", 1)
            options.set_preference("network.proxy.http", host)
            options.set_preference("network.proxy.http_port", int(port))
            options.set_preference("network.proxy.ssl", host)
            options.set_preference("network.proxy.ssl_port", int(port))
            print(Fore.GREEN + f"[+] ä½¿ç”¨ä»£ç†: {proxy}")
        else:
            print(Fore.YELLOW + f"[-] ä»£ç†æ ¼å¼é”™è¯¯: {proxy} (åº”ä¸º host:port)")

    try:
        driver = webdriver.Firefox(service=service, options=options)
        print("æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
        return driver
    except Exception as e:
        print(Fore.RED + f"[-] æµè§ˆå™¨å¯åŠ¨å¤±è´¥: {e}")
        return None


def safe_click(driver):
    """å®‰å…¨ç‚¹å‡»"æ›´å¤šç»“æœ"æŒ‰é’®"""
    for attempt in range(CLICK_RETRY):
        try:
            # ä½¿ç”¨æä¾›çš„ ID å®šä½æŒ‰é’®
            button = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.ID, "more-results"))
            )

            # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
            driver.execute_script("arguments[0].scrollIntoView({block: 'center', behavior: 'smooth'});", button)

            # æ·»åŠ éšæœºå»¶è¿Ÿï¼Œæ›´åƒäººç±»è¡Œä¸º
            time.sleep(random.uniform(0.5, 1))

            # ç‚¹å‡»æŒ‰é’®
            button.click()

            # ç‚¹å‡»åç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(random.uniform(0.2, 1))

            print(Fore.GREEN + f"[+] æˆåŠŸç‚¹å‡»'æ›´å¤šç»“æœ'æŒ‰é’®ï¼ŒåŠ è½½æ›´å¤šå†…å®¹...")
            return True
        except (TimeoutException, StaleElementReferenceException) as e:
            print(Fore.YELLOW + f"[-] æŒ‰é’®ç‚¹å‡»å¤±è´¥ï¼ˆå°è¯• {attempt + 1}/{CLICK_RETRY}ï¼‰ï¼Œé‡è¯•ä¸­...")
            time.sleep(0.25)
        except Exception as e:
            print(Fore.RED + f"[-] ç‚¹å‡»æŒ‰é’®æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            return False

    print(Fore.RED + f"[-] è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•åŠ è½½æ›´å¤šå†…å®¹")
    return False


def force_scroll(driver):
    """å¼ºåˆ¶æ»šåŠ¨é¡µé¢ä»¥ç¡®ä¿æ‰€æœ‰å†…å®¹åŠ è½½"""
    print(Fore.YELLOW + "[+] å¼ºåˆ¶æ»šåŠ¨åŠ è½½é¡µé¢å†…å®¹...")

    last_height = driver.execute_script("return document.body.scrollHeight")

    if last_height == 0:
        print(Fore.YELLOW + "[-] é¡µé¢ä¸ºç©ºï¼Œè·³è¿‡æ»šåŠ¨åŠ è½½")
        return

    while True:
        # æ»šåŠ¨åˆ°åº•éƒ¨
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")

        # ç­‰å¾…é¡µé¢åŠ è½½
        time.sleep(SCROLL_PAUSE)

        # è®¡ç®—æ–°çš„é¡µé¢é«˜åº¦
        new_height = driver.execute_script("return document.body.scrollHeight")

        # å¦‚æœé¡µé¢é«˜åº¦æ²¡æœ‰å˜åŒ–ï¼Œè¯´æ˜å·²ç»åˆ°åº•éƒ¨
        if new_height == last_height:
            break

        last_height = new_height

    # é¢å¤–çš„å°æ»šåŠ¨ï¼Œç¡®ä¿æ‰€æœ‰å…ƒç´ éƒ½è¢«åŠ è½½
    for i in range(3):
        driver.execute_script(f"window.scrollBy(0, -{random.randint(100, 300)});")
        time.sleep(0.25)
        driver.execute_script(f"window.scrollBy(0, {random.randint(100, 300)});")
        time.sleep(0.25)

    print(Fore.YELLOW + "[+] é¡µé¢å†…å®¹åŠ è½½å®Œæˆ")


def extract_subdomains(driver, base_domain):
    """æå–é¡µé¢ä¸Šçš„æ‰€æœ‰å­åŸŸå"""
    subdomains = set()

    # ä½¿ç”¨å¤šç§é€‰æ‹©å™¨ç­–ç•¥ï¼Œæé«˜æå–æˆåŠŸç‡
    selectors = [
        'a[data-testid="result-title-a"]',  # ä¸»è¦é€‰æ‹©å™¨
        'a.result__url',  # å¤‡ç”¨é€‰æ‹©å™¨
        'a[data-testid="result-extras-url"]'  # é¢å¤–å¤‡ç”¨é€‰æ‹©å™¨
    ]

    for selector in selectors:
        try:
            links = driver.find_elements(By.CSS_SELECTOR, selector)
            print(f"ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(links)} ä¸ªé“¾æ¥")

            if not links:
                print(f"é€‰æ‹©å™¨ '{selector}' æœªæ‰¾åˆ°ä»»ä½•é“¾æ¥")
                continue

            for link in links:
                try:
                    href = link.get_attribute('href')
                    if not href or not href.startswith('http'):
                        continue

                    # è§£æåŸŸå
                    extracted = tldextract.extract(href)
                    full_domain = f"{extracted.subdomain}.{extracted.domain}.{extracted.suffix}"

                    # è¿‡æ»¤æ— æ•ˆåŸŸå
                    if not extracted.domain or not extracted.suffix:
                        continue

                    # åªä¿ç•™ä¸ç›®æ ‡åŸŸåç›¸å…³çš„å­åŸŸå
                    if base_domain in full_domain and full_domain != base_domain:
                        subdomains.add(full_domain)
                except StaleElementReferenceException:
                    print("å…ƒç´ å·²è¿‡æœŸï¼Œè·³è¿‡")
                    continue

            # å¦‚æœä½¿ç”¨æŸä¸ªé€‰æ‹©å™¨æ‰¾åˆ°äº†é“¾æ¥ï¼Œå°±ä¸å†å°è¯•å…¶ä»–é€‰æ‹©å™¨
            if links:
                break
        except Exception as e:
            print(f"é€‰æ‹©å™¨ '{selector}' æ‰§è¡Œå‡ºé”™: {e}")

    print(f"æ€»å…±æå–åˆ° {len(subdomains)} ä¸ªå­åŸŸå")
    return subdomains


def crawl_subdomains(driver, query, proxy=None):
    """ä¸»çˆ¬å–é€»è¾‘"""
    # ä»æŸ¥è¯¢ä¸­æå–ç›®æ ‡åŸŸå
    target_domain = query.split(":")[-1].strip()
    if not target_domain:
        print(Fore.RED + "[-] æ— æ•ˆåŸŸåï¼")
        return set(), 0

    # æ„å»ºæœç´¢URL
    search_url = f"https://duckduckgo.com/?q=site:{target_domain}&ia=web"

    try:
        driver.get(search_url)
        print(Fore.GREEN + f"[+] å·²æ‰“å¼€æœç´¢é¡µ: {search_url}")
    except Exception as e:
        print(Fore.RED + f"[-] æ‰“å¼€æœç´¢é¡µå¤±è´¥: {e}")
        return set(), 0

    # é¢„ç•™æ—¶é—´å¤„ç†éªŒè¯ç 
    print(Fore.YELLOW + "[!] è‹¥å‡ºç°éªŒè¯ç ï¼Œè¯·æ‰‹åŠ¨å®ŒæˆéªŒè¯ï¼Œ0.1ç§’åç»§ç»­...ã€å› ä¸ºåŸºæœ¬ä¸ä¼šå‡ºç°éªŒè¯ç ï¼Œåç»­ä¼šä¼˜åŒ–~~~ã€‘")
    time.sleep(0.1)

    all_subdomains = set()
    page_count = 1
    empty_attempts = 0
    start_time = time.time()

    try:
        while empty_attempts < MAX_EMPTY_ATTEMPTS:
            print(Fore.YELLOW + f"\n[+] ç¬¬ {page_count} è½®çˆ¬å– | å¼€å§‹åŠ è½½å†…å®¹...")

            # 1. å¼ºåˆ¶æ»šåŠ¨åŠ è½½é¡µé¢å†…å®¹
            force_scroll(driver)

            # 2. æå–å­åŸŸå
            current_subdomains = extract_subdomains(driver, target_domain)
            new_subdomains = current_subdomains - all_subdomains

            # 3. å¤„ç†æå–ç»“æœ
            if new_subdomains:
                all_subdomains.update(new_subdomains)
                empty_attempts = 0  # é‡ç½®ç©ºç»“æœè®¡æ•°å™¨

                print(
                    Fore.GREEN + f"[+] ç¬¬ {page_count} è½® | æ–°å¢ {len(new_subdomains)} ä¸ªå­åŸŸå | ç´¯è®¡ {len(all_subdomains)}")

                # æ˜¾ç¤ºæ–°å¢å­åŸŸå
                print(Fore.CYAN + "[+] æ–°å¢å­åŸŸååˆ—è¡¨ï¼š")
                for idx, subdomain in enumerate(sorted(new_subdomains), 1):
                    print(Fore.CYAN + f"    {idx}. {subdomain}")
            else:
                empty_attempts += 1
                print(
                    Fore.YELLOW + f"[-] ç¬¬ {page_count} è½® | æœªå‘ç°æ–°å­åŸŸå | ç©ºè½®æ¬¡ {empty_attempts}/{MAX_EMPTY_ATTEMPTS}")

            # 4. ç§»é™¤ä¸´æ—¶æ–‡ä»¶ä¿å­˜é€»è¾‘

            # 5. å°è¯•ç‚¹å‡»"æ›´å¤šç»“æœ"æŒ‰é’®
            if not safe_click(driver):
                print(Fore.YELLOW + "[-] æ— æ³•åŠ è½½æ›´å¤šå†…å®¹ï¼Œç»“æŸçˆ¬å–")
                break

            page_count += 1
    except Exception as e:
        print(Fore.RED + f"[-] çˆ¬å–è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")

    crawl_time = time.time() - start_time
    print(
        Fore.GREEN + f"\n[+] {target_domain} çˆ¬å–å®Œæˆ | æ€»å­åŸŸåæ•°é‡: {len(all_subdomains)} | è€—æ—¶: {crawl_time:.2f} ç§’")

    return all_subdomains, crawl_time


def save_results(subdomains, filename="results.txt"):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    # åˆ›å»ºresultsæ–‡ä»¶å¤¹
    results_dir = "results"
    if not os.path.exists(results_dir):
        os.makedirs(results_dir)
    # æ‹¼æ¥å®Œæ•´è·¯å¾„
    full_path = os.path.join(results_dir, filename)
    try:
        if subdomains:  # åªåœ¨æœ‰ç»“æœæ—¶ä¿å­˜æ–‡ä»¶
            with open(full_path, 'w', encoding='utf-8') as f:
                for domain in subdomains:
                    # å»é™¤å¼€å¤´çš„.
                    if domain.startswith('.'):
                        domain = domain[1:]
                    f.write(domain + '\n')
            print(Fore.YELLOW + f"[+] å·²ä¿å­˜ {len(subdomains)} ä¸ªå­åŸŸååˆ° {full_path}")
            return True
        else:
            print(Fore.YELLOW + f"[!] æ²¡æœ‰æ‰¾åˆ°å­åŸŸåï¼Œä¸ä¼šç”Ÿæˆæ–‡ä»¶")
            return False
    except Exception as e:
        print(Fore.RED + f"[-] ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return False


def send_email(sender_email, sender_password, receiver_email, subject, content):
    # åˆ›å»ºé‚®ä»¶å¯¹è±¡
    message = MIMEMultipart()

    # ä½¿ç”¨ formataddr å‡½æ•°ä¸¥æ ¼æŒ‰ç…§ RFC æ ‡å‡†æ ¼å¼åŒ– From å­—æ®µ
    # å‘ä»¶äººå§“åï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    sender_name = "Python é‚®ä»¶å‘é€"
    message['From'] = formataddr((str(Header(sender_name, 'utf-8')), sender_email))

    message['To'] = receiver_email  # ç›´æ¥ä½¿ç”¨é‚®ç®±åœ°å€ï¼ŒQQé‚®ç®±ä¸æ¥å— Header åŒ…è£…
    message['Subject'] = Header(subject, 'utf-8')

    # æ·»åŠ é‚®ä»¶æ­£æ–‡
    message.attach(MIMEText(content, 'plain', 'utf-8'))

    try:
        # è¿æ¥QQé‚®ç®±SMTPæœåŠ¡å™¨ï¼ˆSSLåŠ å¯†ï¼‰
        smtp_obj = smtplib.SMTP_SSL('smtp.qq.com', 465)
        smtp_obj.login(sender_email, sender_password)

        # å‘é€é‚®ä»¶
        smtp_obj.sendmail(sender_email, [receiver_email], message.as_string())
        print("é‚®ä»¶å‘é€æˆåŠŸï¼")

    except smtplib.SMTPException as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")

    finally:
        # å…³é—­è¿æ¥
        if 'smtp_obj' in locals():
            smtp_obj.quit()


if __name__ == "__main__":
    # ä¸¥æ ¼ä¿æŒåŸæœ‰å‚æ•°ä¸å˜
    parser = argparse.ArgumentParser(description='å­åŸŸæ·±åº¦çˆ¬å–å·¥å…·ï¼ˆä¿®å¤ç‰ˆï¼‰')
    parser.add_argument('--command', type=str, help='ç›®æ ‡åŸŸåï¼ˆæ ¼å¼ï¼šsite:example.comï¼‰')
    parser.add_argument('-f', type=str, help='åŒ…å«åŸŸåçš„æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--proxy', type=str, help='ä½¿ç”¨ä»£ç†æœåŠ¡å™¨ï¼ˆæ ¼å¼ï¼šhost:portï¼‰')
    args = parser.parse_args()

    print_banner()
    create_results_folder()

    proxy = args.proxy

    # åˆå§‹åŒ–æµè§ˆå™¨
    driver = setup_driver(proxy)
    if not driver:
        import sys

        sys.exit(1)

    # ç”¨äºå­˜å‚¨æ‰€æœ‰çˆ¬å–ç»“æœçš„å­—å…¸
    all_results = {}
    total_time = 0

    try:
        if args.f:
            if not os.path.exists(args.f):
                print(Fore.RED + f"[-] æ–‡ä»¶ {args.f} ä¸å­˜åœ¨ï¼")
                sys.exit(1)
            with open(args.f, 'r', encoding='utf-8') as f:
                domains = f.read().splitlines()
            for domain in domains:
                command = f"site:{domain}"
                target_domain = domain
                print(Fore.GREEN + f"[+] å¼€å§‹çˆ¬å– {target_domain} çš„å­åŸŸå...")

                subdomains, crawl_time = crawl_subdomains(driver, command, proxy)
                total_time += crawl_time

                # ä¿å­˜ç»“æœ
                results_file = f"FireFox_results_{target_domain}.txt"
                save_results(subdomains, results_file)

                # ä¿å­˜åˆ°æ€»ç»“æœ
                all_results[target_domain] = {
                    'subdomains': subdomains,
                    'count': len(subdomains),
                    'time': crawl_time,
                    'file': results_file
                }

                # å‡†å¤‡ä¸‹ä¸€ä¸ªåŸŸåï¼Œä¸å…³é—­æµè§ˆå™¨
                print(Fore.YELLOW + f"\n[+] å‡†å¤‡çˆ¬å–ä¸‹ä¸€ä¸ªåŸŸåï¼Œä¿æŒæµè§ˆå™¨æ‰“å¼€...")

        elif args.command:
            target_domain = args.command.split(":")[-1].strip()
            if not target_domain:
                print(Fore.RED + "[-] åŸŸåä¸èƒ½ä¸ºç©ºï¼")
                exit(1)

            print(Fore.GREEN + f"[+] å¼€å§‹çˆ¬å– {target_domain} çš„å­åŸŸå...")

            subdomains, crawl_time = crawl_subdomains(driver, args.command, args.proxy)
            total_time += crawl_time

            # ä¿å­˜ç»“æœ
            results_file = f"FireFox_results_{target_domain}.txt"
            save_results(subdomains, results_file)

            # ä¿å­˜åˆ°æ€»ç»“æœ
            all_results[target_domain] = {
                'subdomains': subdomains,
                'count': len(subdomains),
                'time': crawl_time,
                'file': results_file
            }
        else:
            print(Fore.RED + "[-] è¯·æä¾› --command æˆ– -f å‚æ•°ï¼")

        # ç”Ÿæˆé‚®ä»¶å†…å®¹
        if all_results:
            email_subject = "ğŸ“§ Firefoxçš„Domainä¿¡æ¯æ”¶é›†å·¥ä½œå·²å®Œæˆï¼"
            email_content = "æ‚¨å¥½ï¼å°Šæ•¬çš„è¾‰å°é±¼å…ˆç”Ÿï¼\n\n"
            email_content += "æ‰€æœ‰Domainæ”¶é›†å·¥ä½œå·²å…¨é¢å®Œæˆï¼ä»¥ä¸‹æ˜¯è¯¦ç»†æŠ¥å‘Šï¼š\n\n"

            total_subdomains = 0

            for domain, info in all_results.items():
                email_content += f"ğŸ” ç›®æ ‡åŸŸå: {domain}\n"
                email_content += f"   - å­åŸŸåæ•°é‡: {info['count']}\n"
                email_content += f"   - çˆ¬å–è€—æ—¶: {info['time']:.2f} ç§’\n"
                email_content += f"   - ç»“æœæ–‡ä»¶: {info['file']}\n\n"
                total_subdomains += info['count']

            email_content += f"ğŸ“Š æ€»è®¡çˆ¬å–åŸŸåæ•°: {len(all_results)}\n"
            email_content += f"ğŸ“Š æ€»å­åŸŸåæ•°é‡: {total_subdomains}\n"
            email_content += f"ğŸ•’ æ€»è€—æ—¶: {total_time:.2f} ç§’\n\n"

            email_content += "ç¥æ‚¨æŒ–æ´æ„‰å¿«ï¼Œå¿…å‡ºé«˜å±å“¦~~~\nGoogleFirefoxDomain é‚®ä»¶åŠ©æ‰‹"

            # å‘é€é‚®ä»¶é€šçŸ¥
            sender_email = "1794686508@qq.com"  # ä½ çš„QQé‚®ç®±åœ°å€
            sender_password = "busnjcluyxtlejgc"  # ä½ çš„QQé‚®ç®±SMTPæˆæƒç 
            receiver_email = "shenghui3301@163.com"  # æ”¶ä»¶äººé‚®ç®±åœ°å€

            send_email(sender_email, sender_password, receiver_email, email_subject, email_content)
        else:
            print(Fore.YELLOW + "[!] æ²¡æœ‰çˆ¬å–ä»»ä½•åŸŸåï¼Œä¸ä¼šå‘é€é‚®ä»¶")

    finally:
        # ç¡®ä¿æœ€åå…³é—­æµè§ˆå™¨
        if driver:
            try:
                driver.quit()
                print(Fore.YELLOW + "[+] ä¸»ç¨‹åºä¸­ Firefox æµè§ˆå™¨å·²å…³é—­")
            except Exception as e:
                print(Fore.RED + f"[-] å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {str(e)}")